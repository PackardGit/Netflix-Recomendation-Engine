{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Netflix Recomendations Engine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFCsUMDtbCVT"
      },
      "source": [
        "# 2.0. Recomendations Engine using Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nqgZzx0bMq9"
      },
      "source": [
        "## 2.1. Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYEWLJ579psL",
        "outputId": "de790248-1217-4fec-8b86-9f452c9e336a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install faiss # k-nn  to calculate semantic similarity (FACEBOOK AI SIMILARITY SEARCH)\n",
        "!pip install faiss-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 13.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=35e1f6aebf84bb9263fd67c50f8ce41b48a574a4bce8708853978396e4fcfe36\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting faiss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss) (1.18.5)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n",
            "Collecting faiss-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/6b/1e316d731ce94821854cd54d04b4a0dd3e3c5d47292d9a373b56a8e19a8f/faiss_gpu-1.6.4.post2-cp36-cp36m-manylinux2014_x86_64.whl (67.6MB)\n",
            "\u001b[K     |████████████████████████████████| 67.6MB 42kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.6.4.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdSpyb0nbRwB"
      },
      "source": [
        "## 2.2. Mount Drive and read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngT5N1rK3JUC",
        "outputId": "6113fffa-5a21-4644-d000-b075401f61f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os \n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "COLAB = True\n",
        "print(\"Note: using Google CoLab\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gty8_0of4Wta",
        "outputId": "52602aae-aa0f-4d56-84f4-e101d42f2e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig # model\n",
        "from transformers import BertTokenizer # tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences # add padding\n",
        "import torch\n",
        "import time\n",
        "import faiss # sentence similarity\n",
        "import plotly.express as px #plots\n",
        "\n",
        "FOLDER_PATH = '/content/drive/My Drive/projects/netflix'\n",
        "DATA_FILE_PATH = os.path.join(FOLDER_PATH, 'netflix_titles.csv') \n",
        "df = pd.read_csv(DATA_FILE_PATH,na_values=['NA','?'])\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>show_id</th>\n",
              "      <th>type</th>\n",
              "      <th>title</th>\n",
              "      <th>director</th>\n",
              "      <th>cast</th>\n",
              "      <th>country</th>\n",
              "      <th>date_added</th>\n",
              "      <th>release_year</th>\n",
              "      <th>rating</th>\n",
              "      <th>duration</th>\n",
              "      <th>listed_in</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81145628</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Norm of the North: King Sized Adventure</td>\n",
              "      <td>Richard Finn, Tim Maltby</td>\n",
              "      <td>Alan Marriott, Andrew Toth, Brian Dobson, Cole...</td>\n",
              "      <td>United States, India, South Korea, China</td>\n",
              "      <td>September 9, 2019</td>\n",
              "      <td>2019</td>\n",
              "      <td>TV-PG</td>\n",
              "      <td>90 min</td>\n",
              "      <td>Children &amp; Family Movies, Comedies</td>\n",
              "      <td>Before planning an awesome wedding for his gra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80117401</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Jandino: Whatever it Takes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jandino Asporaat</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>September 9, 2016</td>\n",
              "      <td>2016</td>\n",
              "      <td>TV-MA</td>\n",
              "      <td>94 min</td>\n",
              "      <td>Stand-Up Comedy</td>\n",
              "      <td>Jandino Asporaat riffs on the challenges of ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70234439</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Transformers Prime</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Peter Cullen, Sumalee Montano, Frank Welker, J...</td>\n",
              "      <td>United States</td>\n",
              "      <td>September 8, 2018</td>\n",
              "      <td>2013</td>\n",
              "      <td>TV-Y7-FV</td>\n",
              "      <td>1 Season</td>\n",
              "      <td>Kids' TV</td>\n",
              "      <td>With the help of three human allies, the Autob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80058654</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Transformers: Robots in Disguise</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Will Friedle, Darren Criss, Constance Zimmer, ...</td>\n",
              "      <td>United States</td>\n",
              "      <td>September 8, 2018</td>\n",
              "      <td>2016</td>\n",
              "      <td>TV-Y7</td>\n",
              "      <td>1 Season</td>\n",
              "      <td>Kids' TV</td>\n",
              "      <td>When a prison ship crash unleashes hundreds of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80125979</td>\n",
              "      <td>Movie</td>\n",
              "      <td>#realityhigh</td>\n",
              "      <td>Fernando Lebrija</td>\n",
              "      <td>Nesta Cooper, Kate Walsh, John Michael Higgins...</td>\n",
              "      <td>United States</td>\n",
              "      <td>September 8, 2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>TV-14</td>\n",
              "      <td>99 min</td>\n",
              "      <td>Comedies</td>\n",
              "      <td>When nerdy high schooler Dani finally attracts...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    show_id  ...                                        description\n",
              "0  81145628  ...  Before planning an awesome wedding for his gra...\n",
              "1  80117401  ...  Jandino Asporaat riffs on the challenges of ra...\n",
              "2  70234439  ...  With the help of three human allies, the Autob...\n",
              "3  80058654  ...  When a prison ship crash unleashes hundreds of...\n",
              "4  80125979  ...  When nerdy high schooler Dani finally attracts...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtEn0mTbVlh"
      },
      "source": [
        "## 2.3. Load model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zplsUtQ59xYP",
        "outputId": "5a397937-3c3b-4c9a-afab-4cecbcc09c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "output_dir = '/content/drive/My Drive/projects/netflix'\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "     output_dir,#\"bert-base-uncased\"\n",
        "    output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "     output_dir\n",
        "    )\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPOCbrgVbhQx"
      },
      "source": [
        "## 2.4. Getting embeddings of descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNLxpE3E5NsQ"
      },
      "source": [
        "def time_elapsed(sec):\n",
        "  h = int(sec/3600)\n",
        "  m = int(sec/60)\n",
        "  s = sec % 60\n",
        "  return \"{}:{:>02}:{:>05.2f}\".format(h,m,s)\n",
        "\n",
        "def description_embedding(tokenizer,model,description):\n",
        "  MAX_LEN = 128\n",
        "  # need to format inputs (decriptions)\n",
        "  #  1.Add additional needed tokens\n",
        "  input_ids = tokenizer.encode(\n",
        "                        description,                      \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "  #  2.every input must be the same length, but descriptions are different so me must add padding (adding token id0 to shorter inputs)\n",
        "  results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\", \n",
        "                            truncating=\"post\", padding=\"post\")\n",
        "  input_ids = results[0] #pad sequences requires list of a lists, co to take only one list we make this\n",
        "  #  3. Creating attention masks\n",
        "  attention_masks = [int(token_id > 0) for token_id in input_ids]\n",
        "  # 4. Create torch tensor and add dimension for number of batches (1)\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "  input_ids = input_ids.unsqueeze(0)\n",
        "  attention_masks = attention_masks.unsqueeze(0)\n",
        "  # put model in eval mode\n",
        "  model.eval()\n",
        "  # copy inputs to GPU\n",
        "  input_ids = input_ids.to(device)\n",
        "  attention_masks = attention_masks.to(device)\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "  with torch.no_grad():        \n",
        "    logits, encoded_layers = model(input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=attention_masks)\n",
        "    \n",
        "  layer_nr = 12 #last layer\n",
        "  batch_nr = 0 # nr of inputs in batch 0 = 1\n",
        "  token_nr = 0 # nr of first token\n",
        "  emb_vec = encoded_layers[layer_nr][batch_nr][token_nr]\n",
        "  # Move to cpu\n",
        "  result = emb_vec.detach().cpu().numpy()\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_EtLRFHV2Or",
        "outputId": "b180d49e-bf9e-4b68-afd4-80dfdac0d22f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "descriptions = df.description.values\n",
        "start_time = time.time()\n",
        "embeddings = []\n",
        "# embedding in loop\n",
        "for i, desc in enumerate(descriptions):\n",
        "  embedding = description_embedding(tokenizer,model,desc)\n",
        "  embeddings.append(embedding)\n",
        "  if ((i % 1000 ==0) and (i>0) or (i == len(descriptions)-1)):\n",
        "    elapsed_time = time_elapsed(time.time()-start_time)\n",
        "    print(f'Progress: {round(i/len(descriptions)*100,2)}%')\n",
        "    print(f'Time elapsed: {elapsed_time}')\n",
        "embeddings = np.array(embeddings)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: 16.04%\n",
            "Time elapsed: 0:00:13.06\n",
            "Progress: 32.08%\n",
            "Time elapsed: 0:00:26.24\n",
            "Progress: 48.12%\n",
            "Time elapsed: 0:00:39.45\n",
            "Progress: 64.16%\n",
            "Time elapsed: 0:00:52.07\n",
            "Progress: 80.21%\n",
            "Time elapsed: 0:01:04.76\n",
            "Progress: 96.25%\n",
            "Time elapsed: 0:01:17.71\n",
            "Progress: 99.98%\n",
            "Time elapsed: 0:01:20.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwer6pv3cCR1"
      },
      "source": [
        "After getting embeddings, every description is represented by vector of 768 numbers. We need now to compare them and see which are similar and which are not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7CMsEzubqEL"
      },
      "source": [
        "## 2.5. Initialize FAISS (Facebook AI Similarity Search)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCSvka7xS95v"
      },
      "source": [
        "# k-NN to calculate simillarity\n",
        "# initialize of FAISS\n",
        "cpu_index = faiss.IndexFlatL2(embeddings.shape[1]) #embeddings.shape[1] is number of features in feature vector\n",
        "co = faiss.GpuMultipleClonerOptions()\n",
        "co.shard = True\n",
        "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index, co=co,ngpu=1)\n",
        "gpu_index.add(embeddings) # adding dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CClDMDwTci58"
      },
      "source": [
        "## 2.6. Function to calculate 10 similar movies to the choosen one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfjqrptGZBCy"
      },
      "source": [
        "# function to calculate recomendations\n",
        "indices = pd.Series(df.index, index=df['title']).drop_duplicates()\n",
        "def get_recomendations(title):\n",
        "  idx = indices[title]\n",
        "  distances, movies = gpu_index.search(embeddings[idx].reshape(1,768),k=11)\n",
        "  movie_titles = []\n",
        "  for i in range(movies.shape[1]-1):\n",
        "    movie_titles.append(df.iloc[movies[0,i+1]].title)\n",
        "  likehood = (1-distances[0,1:]/(max(max(distances)))*0.9)\n",
        "  likehood = likehood/max(likehood)\n",
        "  return movie_titles,likehood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUTxxc7XcsVV"
      },
      "source": [
        "## 2.7. Choose your movie here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbzeQcLOi2NW"
      },
      "source": [
        "movie_you_watched = 'The Two Popes'\n",
        "recomendations, likehood = get_recomendations(movie_you_watched)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttCAnvVbcyu2"
      },
      "source": [
        "## 2.8. Create plot with recomendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acJqk0lNbILM",
        "outputId": "e554466b-5232-4c8b-e7b8-a29ea518163b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "# creating plot with recomendations\n",
        "df_temp = pd.DataFrame(columns = df.columns)\n",
        "temp_tittle=[]\n",
        "for i,t in enumerate(recomendations):\n",
        "  df_temp = df_temp.append(df[(df.title==t)])\n",
        "  temp_tittle.append(' ')\n",
        "\n",
        "plot_title = 'Recomendations after watching ' + movie_you_watched \n",
        "fig = px.treemap(\n",
        "    data_frame = df_temp,\n",
        "    names = df_temp['title'],\n",
        "    values = likehood,\n",
        "    parents = temp_tittle,\n",
        "    hover_name = df_temp['title'],\n",
        "    hover_data=['director','release_year','rating','country','cast'],\n",
        "    title = plot_title\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"b6b72089-9cf2-4eb0-afd6-dfe67fef8038\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"b6b72089-9cf2-4eb0-afd6-dfe67fef8038\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'b6b72089-9cf2-4eb0-afd6-dfe67fef8038',\n",
              "                        [{\"customdata\": [[null, 2016, \"TV-14\", null, \"Nawat Kulrattanarak, Woranuch Wongsawan, Jespipat Tilapornputt, Paramej Noiam, Phutharit Prombandal\"], [null, 2010, \"TV-PG\", \"Mexico\", \"Milia Nader, Francisco Avenda\\u00f1o, Diego Lara, Sandra Itzel, Marisol del Olmo, Aleyda Gallardo, Gerardo Murgu\\u00eda, Roxana Saucedo, Emmanuel Orenday, Maru Due\\u00f1as\"], [null, 1988, \"TV-PG\", \"United States\", \"Michael Landon, Victor French\"], [\"David Batty\", 2015, \"TV-14\", \"United States, United Kingdom, Morocco\", \"Selva Rasalingam, Karima Gouit, Mourad Zaoui, El Mahmoudi M'Barek, Abdelilah Wahbi, Abdelaziz N'Mila, Ait Youssef Youssef, Mohamed El Korchi, Ramdane Aala\"], [null, 2013, \"TV-G\", \"United Kingdom\", \"Alan Titchmarsh, David Domoney, Frances Tophill, Katie Rushworth\"], [\"Rajeev Patil\", 2008, \"TV-14\", \"India\", \"Shreyas Talpade, Subodh Bhave, Sai Tamhankar, Santosh Juvekar, Tushar Dalvi, Bharti Aacharekar\"], [\"Karan Shivajirao Chavan, Vikram Tanajirao Patil\", 2018, \"TV-PG\", \"India\", \"Aishwarya Ghaydar, Amol Deshmukh, Adarsh Kurne, Vishwas Kamble, Neha Awati, Amaraja Patil, Rinkle Chopde, Shreyas Gurav\"], [null, 2017, \"TV-PG\", \"India\", \"Rasika Dugal, Devdutt Pattanaik\"], [null, 2018, \"PG\", \"United Kingdom\", null], [\"Will Lovelace, Dylan Southern\", 2013, \"NR\", \"United States\", \"Aziz Ansari\"]], \"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"<b>%{hovertext}</b><br><br>director=%{customdata[0]}<br>release_year=%{customdata[1]}<br>rating=%{customdata[2]}<br>country=%{customdata[3]}<br>cast=%{customdata[4]}<br>title=%{label}<br>value=%{value}<br>parent=%{parent}\", \"hovertext\": [\"Blood & Treasures\", \"La Rosa de Guadalupe\", \"Highway to Heaven\", \"The Gospel of Luke\", \"Love Your Garden\", \"Sanai Choughade\", \"Imago\", \"Devlok with Devdutt Pattanaik\", \"The Repair Shop\", \"Aziz Ansari: Buried Alive\"], \"labels\": [\"Blood & Treasures\", \"La Rosa de Guadalupe\", \"Highway to Heaven\", \"The Gospel of Luke\", \"Love Your Garden\", \"Sanai Choughade\", \"Imago\", \"Devlok with Devdutt Pattanaik\", \"The Repair Shop\", \"Aziz Ansari: Buried Alive\"], \"name\": \"\", \"parents\": [\" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \"], \"type\": \"treemap\", \"values\": [1.0, 0.9393123984336853, 0.7532936930656433, 0.7368240356445312, 0.6623057126998901, 0.6081188321113586, 0.5652492046356201, 0.5466616749763489, 0.5304800868034363, 0.5197709798812866]}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Recomendations after watching The Two Popes\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b6b72089-9cf2-4eb0-afd6-dfe67fef8038');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}